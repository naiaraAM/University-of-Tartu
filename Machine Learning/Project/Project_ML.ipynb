{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/naiaraAM/ML_project_UT/blob/main/Project_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzV8D8bXC4lw"
   },
   "source": [
    "# Set up enviroment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrh42OERGJnQ"
   },
   "source": [
    "# Download data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "MobMyN7kGOZS",
    "outputId": "e36928ec-8f8b-4f07-c8a1-6795bd4b8c92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open playground-series-s4e6.zip, playground-series-s4e6.zip.zip or playground-series-s4e6.zip.ZIP.\n",
      "rm: playground-series-s4e6.zip: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!unzip -q playground-series-s4e6.zip -d data\n",
    "!rm playground-series-s4e6.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAKgcDH_F13K",
    "outputId": "ef4a9512-2644-4c37-85b7-5aadaf4304e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data has 76518 rows and 38 columns\n",
      "The test data has 51012 rows and 37 columns\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f\"The train data has {train_data.shape[0]} rows and {train_data.shape[1]} columns\")\n",
    "print(f\"The test data has {test_data.shape[0]} rows and {test_data.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Do your code in the cell bellow your name, so we don't have merge issues. We can merge on friday's meeting</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naiara\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: Marital status\n",
      "Processing feature: Application mode\n",
      "Processing feature: Application order\n",
      "Processing feature: Course\n",
      "Processing feature: Daytime/evening attendance\n",
      "Error processing feature Daytime/evening attendance: [Errno 2] No such file or directory: '/Users/fidansuleymanova/ML_project_UT/plots/Daytime/evening attendance_percentage_plot.png'\n",
      "Processing feature: Previous qualification\n",
      "Processing feature: Nacionality\n",
      "Processing feature: Mother's qualification\n",
      "Processing feature: Father's qualification\n",
      "Processing feature: Mother's occupation\n",
      "Processing feature: Father's occupation\n",
      "Processing feature: Displaced\n",
      "Processing feature: Educational special needs\n",
      "Processing feature: Debtor\n",
      "Processing feature: Tuition fees up to date\n",
      "Processing feature: Gender\n",
      "Processing feature: Scholarship holder\n",
      "Processing feature: Age at enrollment\n",
      "Processing feature: International\n",
      "Processing feature: Curricular units 1st sem (credited)\n",
      "Processing feature: Curricular units 1st sem (enrolled)\n",
      "Processing feature: Curricular units 1st sem (evaluations)\n",
      "Processing feature: Curricular units 1st sem (approved)\n",
      "Processing feature: Curricular units 1st sem (without evaluations)\n",
      "Processing feature: Curricular units 2nd sem (credited)\n",
      "Processing feature: Curricular units 2nd sem (enrolled)\n",
      "Processing feature: Curricular units 2nd sem (evaluations)\n",
      "Processing feature: Curricular units 2nd sem (approved)\n",
      "Processing feature: Curricular units 2nd sem (without evaluations)\n",
      "Processing feature: Unemployment rate\n",
      "Processing feature: Inflation rate\n",
      "Processing feature: GDP\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import matplotlib\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "\n",
    "features = train_data.columns[:-1]\n",
    "\n",
    "max_unique_values = 100  # Different possible values for feature\n",
    "features = [f for f in features if train_data[f].nunique() <= max_unique_values]\n",
    "\n",
    "output_dir = 'plots'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "batch_size = 5\n",
    "for i in range(0, len(features), batch_size):\n",
    "    batch_features = features[i:i + batch_size]\n",
    "    \n",
    "    for feature in batch_features:\n",
    "        try:\n",
    "            print(f\"Processing feature: {feature}\")\n",
    "            percentage = train_data.groupby(feature)['Target'].value_counts(normalize=True).unstack() * 100\n",
    "            \n",
    "            # Plot and save\n",
    "            ax = percentage.plot(kind='bar', stacked=True, colormap='viridis', legend=False)\n",
    "            plt.xlabel(feature)\n",
    "            plt.ylabel('Percentage')\n",
    "            plt.title(f'Percentage of Each Target Value per {feature} Value')\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            plt.legend(handles, labels, title='Target')\n",
    "\n",
    "            # Save plot\n",
    "            plot_filename = os.path.join(output_dir, f'{feature}_percentage_plot.png')\n",
    "            plt.savefig(plot_filename)\n",
    "            plt.close()\n",
    "            #print(f\"Saved plot for feature: {feature}\")\n",
    "            \n",
    "            time.sleep(0.5)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing feature {feature}: {e}\")\n",
    "\n",
    "        gc.collect()  # Clear memory\n",
    "    \n",
    "    #print(f\"Batch {i // batch_size + 1} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submitModel(model, X_test):\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    Y_tilda = model.predict(X_test_scaled)\n",
    "    submission = pd.DataFrame(\n",
    "        {'id': X_test[\"id\"], 'Target': Y_tilda},\n",
    "        columns = ['id', 'Target'])\n",
    "    submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[55], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m submitModel(\u001B[43mbest_model\u001B[49m, test_data) \u001B[38;5;66;03m# 0.82420\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "submitModel(best_model, test_data) # 0.82420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(models, filename: str):\n",
    "    for index, model in enumerate(models):\n",
    "        filename_aux = filename + f'_{index}.pkl'\n",
    "        with open(filename_aux, 'wb') as file:  \n",
    "            pickle.dump(model, file)\n",
    "            print(f\"Saved with the name {filename_aux}\")\n",
    "\n",
    "# TODO: I need to fix this\n",
    "def load_model(filename: str):\n",
    "    with open(filename, 'rb') as file:  \n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-equal performance on public-private score, public is always better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "X = train_data.iloc[:, :-1]\n",
    "y = train_data.iloc[:, -1]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(y.value_counts())\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "gbt_model = GradientBoostingClassifier(n_estimators=350, learning_rate=0.03, max_depth=5)\n",
    "\n",
    "gbt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = gbt_model.predict(X_val)\n",
    "\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "print(f\"Validation Accuracy: {accuracy_val:.4f}\")\n",
    "\n",
    "print(classification_report(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"XXXXX_gbt_model.pkl\"\n",
    "save_model(filename)\n",
    "#model = load_model(filename)\n",
    "\n",
    "y_test = model.predict(X_test_pca)\n",
    "y_test = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'id': test_data[\"id\"], 'Target': y_test},\n",
    "    columns=['id', 'Target']\n",
    ")\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_depth = {\n",
    "    'n_estimators': [200, 200, 200, 200, 200, 200, 200, 200, 200],\n",
    "    'learning_rate': [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05],\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'accuracy': [0.8149, 0.8225, 0.8268, 0.8265, 0.8218, 0.8317, 0.8295, 0.8308, 0.8300],\n",
    "    'private score': [0.82227, 0.82737, 0.83055, 0.83124, 0.83094, 0.83119, 0.82378, 0.82337, 0.82276],\n",
    "    'public score': [0.81915, 0.82513, 0.82915, 0.83022, 0.83199, 0.83120, 0.83150, 0.82111, 0.81866]\n",
    "}\n",
    "\n",
    "df_depth = pd.DataFrame(data_depth)\n",
    "\n",
    "df_styled = df_depth.style.background_gradient(subset=[\"accuracy\", \"public score\", \"private score\"], cmap=\"RdYlGn\", vmin=0.8148, vmax=0.84)\n",
    "\n",
    "df_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_learning_rate = {\n",
    "    'n_estimators': [200, 200, 200, 200, 200, 200],\n",
    "    'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06],\n",
    "    'max_depth': [6, 6, 6, 6, 6, 6],\n",
    "    'accuracy': [0.8228, 0.8291, 0.8304, 0.8304, 0.8306, 0.8298],\n",
    "    'private score': [0.82599, 0.82969, 0.83126, 0.83094, 0.82967, 0.82435],\n",
    "    'public score': [0.82464, 0.82826, 0.82856, 0.83071, 0.83179, 0.82415]\n",
    "}\n",
    "\n",
    "df_learning_rate = pd.DataFrame(data_learning_rate)\n",
    "\n",
    "df_styled = df_learning_rate.style.background_gradient(subset=[\"accuracy\", \"public score\", \"private score\"], cmap=\"RdYlGn\", vmin=0.821, vmax=0.84)\n",
    "\n",
    "df_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_estimators = {\n",
    "    'n_estimators': [50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300],\n",
    "    'learning_rate': [0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03],\n",
    "    'max_depth': [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6],\n",
    "    'accuracy': [0.8200, 0.8248, 0.8276, 0.8284, 0.8292, 0.8296, 0.8304, 0.8306, 0.8314, 0.8311, 0.8314],\n",
    "    'private score': [0.82349, 0.82683, 0.82854, 0.82967, 0.83092, 0.83109, 0.83146, 0.83002, 0.83033, 0.83075, 0.83053],\n",
    "    'public score': [0.82268, 0.82503, 0.82738, 0.82866, 0.82866, 0.82875, 0.82787, 0.83022, 0.83091, 0.83052, 0.83120]\n",
    "}\n",
    "\n",
    "df_estimators = pd.DataFrame(data_estimators)\n",
    "\n",
    "df_styled = df_estimators.style.background_gradient(subset=[\"accuracy\", \"public score\", \"private score\"], cmap=\"RdYlGn\", vmin=0.8148, vmax=0.84)\n",
    "\n",
    "df_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_estimators = {\n",
    "    'n_estimators': [300, 350],\n",
    "    'learning_rate': [0.03, 0.03],\n",
    "    'max_depth': [5, 5],\n",
    "    'private score': [0.83080, 0.83082],\n",
    "    'public score': [0.83189, 0.83238]\n",
    "}\n",
    "\n",
    "df_estimators = pd.DataFrame(data_estimators)\n",
    "\n",
    "df_styled = df_estimators.style.background_gradient(subset=[\"public score\", \"private score\"], cmap=\"RdYlGn\", vmin=0.8148, vmax=0.84)\n",
    "\n",
    "df_styled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has similar performance on private-public, but the other approach is better.\n",
    "\n",
    "What this approach does. Separated the tags into three groups:\n",
    "* 0 and 1 (after label encoder)\n",
    "* 0 and 2 (after label encoder)\n",
    "* 1 and 2 (after label encoder)\n",
    "  \n",
    "Train the three models separately. Then combines\n",
    "* if prediction from `model_01` and `model_02`, then prediction is `0`\n",
    "* if prediction from `model_01` and `model_12`, then prediction is `1`\n",
    "* if prediction from `model_02` and `model_12`, then prediction is `2`\n",
    "* else majority voting\n",
    "\n",
    "I realised that the models struggle to predict for class `1`. If I change the `GradientBoostingClassifier` to `HistGradientBoostingClassifier` it performs a little b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "X = train_data.iloc[:, :-1]\n",
    "y = train_data.iloc[:, -1]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "X_train_01 = X_train[(y_train == 0) | (y_train == 1)]\n",
    "y_train_01 = y_train[(y_train == 0) | (y_train == 1)]\n",
    "X_val_01 = X_val[(y_val == 0) | (y_val == 1)]\n",
    "y_val_01 = y_val[(y_val == 0) | (y_val == 1)]\n",
    "\n",
    "X_train_02 = X_train[(y_train == 0) | (y_train == 2)]\n",
    "y_train_02 = y_train[(y_train == 0) | (y_train == 2)]\n",
    "X_val_02 = X_val[(y_val == 0) | (y_val == 2)]\n",
    "y_val_02 = y_val[(y_val == 0) | (y_val == 2)]\n",
    "\n",
    "X_train_12 = X_train[(y_train == 1) | (y_train == 2)]\n",
    "y_train_12 = y_train[(y_train == 1) | (y_train == 2)]\n",
    "X_val_12 = X_val[(y_val == 1) | (y_val == 2)]\n",
    "y_val_12 = y_val[(y_val == 1) | (y_val == 2)]\n",
    "\n",
    "model_01 = GradientBoostingClassifier(n_estimators=350, learning_rate=0.03, max_depth=5)\n",
    "model_01.fit(X_train_01, y_train_01)\n",
    "y_pred_val_01 = model_01.predict(X_val_01)\n",
    "accuracy_val = accuracy_score(y_val_01, y_pred_val_01)\n",
    "print(f\"Validation Accuracy for model 01: {accuracy_val:.4f}\")\n",
    "print(classification_report(y_val_01, y_pred_val_01))\n",
    "\n",
    "model_02 = GradientBoostingClassifier(n_estimators=350, learning_rate=0.03, max_depth=5)\n",
    "model_02.fit(X_train_02, y_train_02)\n",
    "y_pred_val_02 = model_02.predict(X_val_02)\n",
    "accuracy_val = accuracy_score(y_val_02, y_pred_val_02)\n",
    "print(f\"Validation Accuracy for model 02: {accuracy_val:.4f}\")\n",
    "print(classification_report(y_val_02, y_pred_val_02))\n",
    "\n",
    "model_12 = GradientBoostingClassifier(n_estimators=350, learning_rate=0.03, max_depth=5)\n",
    "model_12.fit(X_train_12, y_train_12)\n",
    "y_pred_val_12 = model_12.predict(X_val_12)\n",
    "accuracy_val = accuracy_score(y_val_12, y_pred_val_12)\n",
    "print(f\"Validation Accuracy for model 12: {accuracy_val:.4f}\")\n",
    "print(classification_report(y_val_12, y_pred_val_12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "def predict(X_data):\n",
    "    final_predictions = []\n",
    "    \n",
    "    for X_pred_data in X_data:\n",
    "        # Predictions for every model\n",
    "        predict_01 = model_01.predict([X_pred_data])[0]\n",
    "        predict_02 = model_02.predict([X_pred_data])[0]\n",
    "        predict_12 = model_12.predict([X_pred_data])[0]\n",
    "        \n",
    "        if predict_01 == predict_02:  # High chance of being class 0\n",
    "            prediction = 0\n",
    "        elif predict_01 == predict_12:  # High change of being class 1\n",
    "            prediction = 1\n",
    "        elif predict_02 == predict_12:  # High chance of being class 2\n",
    "            prediction = 2\n",
    "        else:  # mayority voto\n",
    "            votes = [predict_01, predict_02, predict_12]\n",
    "            prediction = max(set(votes), key=votes.count)\n",
    "        final_predictions.append(prediction)\n",
    "    return np.array(final_predictions)\n",
    "    \n",
    "final_predictions = predict(X_val)\n",
    "\n",
    "accuracy_val_ensemble = accuracy_score(y_val, final_predictions)\n",
    "print(f\"Validation Accuracy for Ensemble Model: {accuracy_val_ensemble:.4f}\")\n",
    "\n",
    "print(classification_report(y_val, final_predictions, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_01, model_02, model_12]\n",
    "filename = \"XXXXX_gbc_ensemble_model\"\n",
    "save_model(models, filename)\n",
    "#model = load_model(filename)\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(test_data)\n",
    "final_predictions = predict(X_scaled)\n",
    "y_test = label_encoder.inverse_transform(final_predictions)\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'id': test_data[\"id\"], 'Target': y_test},\n",
    "    columns=['id', 'Target']\n",
    ")\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = train_data.drop(columns=['Target']), train_data['Target']\n",
    "X.shape, Y.shape, train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_Scaled = scaler.fit_transform(X) # normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, random_state = 111, test_size = 0.20)\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagger = BaggingClassifier(estimator=DecisionTreeClassifier(), max_samples=1.0, n_estimators=9, random_state=1111)\n",
    "score = cross_val_score(bagger, X_Scaled, Y, cv=4)\n",
    "print(f'Average validation accuracy is {np.mean(score)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomF = RandomForestClassifier()\n",
    "score = cross_val_score(randomF, X, Y, cv=4)\n",
    "print(f'Average validation accuracy is {np.mean(score)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomF = RandomForestClassifier()\n",
    "score = cross_val_score(randomF, X_Scaled, Y, cv=4)\n",
    "print(f'Average validation accuracy is {np.mean(score)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomF100 = RandomForestClassifier(n_estimators=100, max_features=\"sqrt\")\n",
    "randomF100.fit(X_train,Y_train)\n",
    "randomF100.score(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomF1000 = RandomForestClassifier(n_estimators=1000, max_features=\"sqrt\")\n",
    "randomF1000.fit(X_train,Y_train)\n",
    "randomF1000.score(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submitModel(model, X_test):\n",
    "    Y_tilda = model.predict(X_test)\n",
    "    submission = pd.DataFrame(\n",
    "        {'id': X_test[\"id\"], 'Target': Y_tilda},\n",
    "        columns = ['id', 'Target'])\n",
    "    submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitModel(randomF1000, test_data) #0.82982\n",
    "submitModel(randomF100, test_data) #0.82523"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fidan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "X_train = train_data.iloc[:, :-1].values  \n",
    "y_train = train_data.iloc[:, -1].values      \n",
    "\n",
    "# normalize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(test_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_scaled, y_train_encoded, test_size=0.2, random_state=42, stratify=y_train_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_final, label=y_train_final)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"multi:softmax\", \n",
    "    \"num_class\": len(np.unique(y_train_encoded)), \n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"eta\": 0.1, \n",
    "    \"max_depth\": 6 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 100\n",
    "early_stopping_rounds = 10\n",
    "evals = [(dtrain, 'train'), (dval, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.01248\teval-mlogloss:1.01330\n",
      "[1]\ttrain-mlogloss:0.94029\teval-mlogloss:0.94205\n",
      "[2]\ttrain-mlogloss:0.87916\teval-mlogloss:0.88181\n",
      "[3]\ttrain-mlogloss:0.82690\teval-mlogloss:0.83042\n",
      "[4]\ttrain-mlogloss:0.78183\teval-mlogloss:0.78608\n",
      "[5]\ttrain-mlogloss:0.74282\teval-mlogloss:0.74781\n",
      "[6]\ttrain-mlogloss:0.70880\teval-mlogloss:0.71447\n",
      "[7]\ttrain-mlogloss:0.67899\teval-mlogloss:0.68542\n",
      "[8]\ttrain-mlogloss:0.65280\teval-mlogloss:0.65986\n",
      "[9]\ttrain-mlogloss:0.62965\teval-mlogloss:0.63729\n",
      "[10]\ttrain-mlogloss:0.60905\teval-mlogloss:0.61718\n",
      "[11]\ttrain-mlogloss:0.59101\teval-mlogloss:0.59978\n",
      "[12]\ttrain-mlogloss:0.57485\teval-mlogloss:0.58407\n",
      "[13]\ttrain-mlogloss:0.56061\teval-mlogloss:0.57026\n",
      "[14]\ttrain-mlogloss:0.54791\teval-mlogloss:0.55813\n",
      "[15]\ttrain-mlogloss:0.53661\teval-mlogloss:0.54733\n",
      "[16]\ttrain-mlogloss:0.52647\teval-mlogloss:0.53769\n",
      "[17]\ttrain-mlogloss:0.51721\teval-mlogloss:0.52898\n",
      "[18]\ttrain-mlogloss:0.50896\teval-mlogloss:0.52135\n",
      "[19]\ttrain-mlogloss:0.50160\teval-mlogloss:0.51458\n",
      "[20]\ttrain-mlogloss:0.49503\teval-mlogloss:0.50850\n",
      "[21]\ttrain-mlogloss:0.48913\teval-mlogloss:0.50312\n",
      "[22]\ttrain-mlogloss:0.48373\teval-mlogloss:0.49818\n",
      "[23]\ttrain-mlogloss:0.47879\teval-mlogloss:0.49368\n",
      "[24]\ttrain-mlogloss:0.47427\teval-mlogloss:0.48962\n",
      "[25]\ttrain-mlogloss:0.47019\teval-mlogloss:0.48600\n",
      "[26]\ttrain-mlogloss:0.46635\teval-mlogloss:0.48263\n",
      "[27]\ttrain-mlogloss:0.46273\teval-mlogloss:0.47944\n",
      "[28]\ttrain-mlogloss:0.45952\teval-mlogloss:0.47675\n",
      "[29]\ttrain-mlogloss:0.45641\teval-mlogloss:0.47425\n",
      "[30]\ttrain-mlogloss:0.45374\teval-mlogloss:0.47205\n",
      "[31]\ttrain-mlogloss:0.45120\teval-mlogloss:0.46998\n",
      "[32]\ttrain-mlogloss:0.44873\teval-mlogloss:0.46799\n",
      "[33]\ttrain-mlogloss:0.44655\teval-mlogloss:0.46642\n",
      "[34]\ttrain-mlogloss:0.44441\teval-mlogloss:0.46487\n",
      "[35]\ttrain-mlogloss:0.44243\teval-mlogloss:0.46334\n",
      "[36]\ttrain-mlogloss:0.44061\teval-mlogloss:0.46201\n",
      "[37]\ttrain-mlogloss:0.43893\teval-mlogloss:0.46064\n",
      "[38]\ttrain-mlogloss:0.43732\teval-mlogloss:0.45947\n",
      "[39]\ttrain-mlogloss:0.43576\teval-mlogloss:0.45842\n",
      "[40]\ttrain-mlogloss:0.43434\teval-mlogloss:0.45753\n",
      "[41]\ttrain-mlogloss:0.43290\teval-mlogloss:0.45647\n",
      "[42]\ttrain-mlogloss:0.43160\teval-mlogloss:0.45575\n",
      "[43]\ttrain-mlogloss:0.43024\teval-mlogloss:0.45489\n",
      "[44]\ttrain-mlogloss:0.42893\teval-mlogloss:0.45412\n",
      "[45]\ttrain-mlogloss:0.42771\teval-mlogloss:0.45336\n",
      "[46]\ttrain-mlogloss:0.42652\teval-mlogloss:0.45255\n",
      "[47]\ttrain-mlogloss:0.42543\teval-mlogloss:0.45191\n",
      "[48]\ttrain-mlogloss:0.42431\teval-mlogloss:0.45131\n",
      "[49]\ttrain-mlogloss:0.42325\teval-mlogloss:0.45076\n",
      "[50]\ttrain-mlogloss:0.42227\teval-mlogloss:0.45021\n",
      "[51]\ttrain-mlogloss:0.42131\teval-mlogloss:0.44968\n",
      "[52]\ttrain-mlogloss:0.42028\teval-mlogloss:0.44908\n",
      "[53]\ttrain-mlogloss:0.41934\teval-mlogloss:0.44866\n",
      "[54]\ttrain-mlogloss:0.41839\teval-mlogloss:0.44814\n",
      "[55]\ttrain-mlogloss:0.41740\teval-mlogloss:0.44762\n",
      "[56]\ttrain-mlogloss:0.41644\teval-mlogloss:0.44721\n",
      "[57]\ttrain-mlogloss:0.41561\teval-mlogloss:0.44692\n",
      "[58]\ttrain-mlogloss:0.41460\teval-mlogloss:0.44647\n",
      "[59]\ttrain-mlogloss:0.41368\teval-mlogloss:0.44603\n",
      "[60]\ttrain-mlogloss:0.41282\teval-mlogloss:0.44575\n",
      "[61]\ttrain-mlogloss:0.41204\teval-mlogloss:0.44545\n",
      "[62]\ttrain-mlogloss:0.41138\teval-mlogloss:0.44518\n",
      "[63]\ttrain-mlogloss:0.41052\teval-mlogloss:0.44507\n",
      "[64]\ttrain-mlogloss:0.40979\teval-mlogloss:0.44473\n",
      "[65]\ttrain-mlogloss:0.40906\teval-mlogloss:0.44453\n",
      "[66]\ttrain-mlogloss:0.40826\teval-mlogloss:0.44432\n",
      "[67]\ttrain-mlogloss:0.40763\teval-mlogloss:0.44412\n",
      "[68]\ttrain-mlogloss:0.40674\teval-mlogloss:0.44378\n",
      "[69]\ttrain-mlogloss:0.40621\teval-mlogloss:0.44361\n",
      "[70]\ttrain-mlogloss:0.40550\teval-mlogloss:0.44343\n",
      "[71]\ttrain-mlogloss:0.40461\teval-mlogloss:0.44306\n",
      "[72]\ttrain-mlogloss:0.40395\teval-mlogloss:0.44286\n",
      "[73]\ttrain-mlogloss:0.40323\teval-mlogloss:0.44275\n",
      "[74]\ttrain-mlogloss:0.40262\teval-mlogloss:0.44250\n",
      "[75]\ttrain-mlogloss:0.40193\teval-mlogloss:0.44238\n",
      "[76]\ttrain-mlogloss:0.40120\teval-mlogloss:0.44225\n",
      "[77]\ttrain-mlogloss:0.40057\teval-mlogloss:0.44207\n",
      "[78]\ttrain-mlogloss:0.40002\teval-mlogloss:0.44189\n",
      "[79]\ttrain-mlogloss:0.39929\teval-mlogloss:0.44169\n",
      "[80]\ttrain-mlogloss:0.39856\teval-mlogloss:0.44147\n",
      "[81]\ttrain-mlogloss:0.39816\teval-mlogloss:0.44136\n",
      "[82]\ttrain-mlogloss:0.39741\teval-mlogloss:0.44113\n",
      "[83]\ttrain-mlogloss:0.39678\teval-mlogloss:0.44109\n",
      "[84]\ttrain-mlogloss:0.39606\teval-mlogloss:0.44094\n",
      "[85]\ttrain-mlogloss:0.39540\teval-mlogloss:0.44073\n",
      "[86]\ttrain-mlogloss:0.39494\teval-mlogloss:0.44064\n",
      "[87]\ttrain-mlogloss:0.39430\teval-mlogloss:0.44043\n",
      "[88]\ttrain-mlogloss:0.39375\teval-mlogloss:0.44031\n",
      "[89]\ttrain-mlogloss:0.39313\teval-mlogloss:0.44020\n",
      "[90]\ttrain-mlogloss:0.39248\teval-mlogloss:0.44002\n",
      "[91]\ttrain-mlogloss:0.39194\teval-mlogloss:0.43995\n",
      "[92]\ttrain-mlogloss:0.39136\teval-mlogloss:0.43986\n",
      "[93]\ttrain-mlogloss:0.39090\teval-mlogloss:0.43971\n",
      "[94]\ttrain-mlogloss:0.39027\teval-mlogloss:0.43968\n",
      "[95]\ttrain-mlogloss:0.38969\teval-mlogloss:0.43963\n",
      "[96]\ttrain-mlogloss:0.38902\teval-mlogloss:0.43952\n",
      "[97]\ttrain-mlogloss:0.38842\teval-mlogloss:0.43931\n",
      "[98]\ttrain-mlogloss:0.38790\teval-mlogloss:0.43919\n",
      "[99]\ttrain-mlogloss:0.38728\teval-mlogloss:0.43914\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(params, dtrain, num_boost_round, evals=evals, early_stopping_rounds=early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "y_test_pred = model.predict(dtest)\n",
    "\n",
    "predicted_labels = label_encoder.inverse_transform(y_test_pred.astype(int))\n",
    "\n",
    "def submitModelPredictedLabels(predicted_labels, X_test):\n",
    "    submission = pd.DataFrame(\n",
    "        {'id': test_data[\"id\"], 'Target': predicted_labels},\n",
    "        columns=['id', 'Target']\n",
    "    )\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"Submission file saved as 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fidansuleymanova/ML_project_UT/venv/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'naiara_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m assabler \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame()\n\u001B[1;32m      2\u001B[0m X_test_scaled \u001B[38;5;241m=\u001B[39m scaler\u001B[38;5;241m.\u001B[39mtransform(test_data)\n\u001B[0;32m----> 3\u001B[0m assabler[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel1\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mnaiara_model\u001B[49m\u001B[38;5;241m.\u001B[39mpredict(X_test_scaled)\n\u001B[1;32m      4\u001B[0m assabler[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel2\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m randomF1000\u001B[38;5;241m.\u001B[39mpredict(test_data)\n\u001B[1;32m      5\u001B[0m assabler[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel3\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m predicted_labels\n",
      "\u001B[0;31mNameError\u001B[0m: name 'naiara_model' is not defined"
     ]
    }
   ],
   "source": [
    "assabler = pd.DataFrame()\n",
    "X_test_scaled = scaler.transform(test_data)\n",
    "assabler[\"model1\"] = naiara_model.predict(X_test_scaled)\n",
    "assabler[\"model2\"] = randomF1000.predict(test_data)\n",
    "assabler[\"model3\"] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "submitModelPredictedLabels(predicted_labels, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assabler['ensemble'] = assabler[[\"model1\", \"model2\", \"model3\"]].mode(axis=1)[0]\n",
    "print(assabler['ensemble'].head())\n",
    "submitModelPredictedLabels(assabler['ensemble'], test_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
